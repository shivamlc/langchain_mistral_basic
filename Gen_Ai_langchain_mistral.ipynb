{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMKaNJHb1xEQ5PW4iYXCTIs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivamlc/langchain_mistral_basic/blob/main/Gen_Ai_langchain_mistral.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HrNNxxNwP7tF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d05a431-4c4a-4731-bf9b-ecf97a28b2e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n",
            "F2KIkuhpkvFkde5dlIXpRR3zwnHECSV5\n"
          ]
        }
      ],
      "source": [
        "# storing env vars in colab\n",
        "from google.colab import userdata\n",
        "\n",
        "langchain_api_key=userdata.get('LANGCHAIN_API_KEY')\n",
        "mistral_api_key=userdata.get('MISTRAL_API_KEY')\n",
        "print(langchain_api_key)\n",
        "print(mistral_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDZy31cj9J4i",
        "outputId": "dbdcf338-bff0-4b95-eef5-470651b53de8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (0.3.26)\n",
            "Collecting python-dotenv (from -r requirements.txt (line 2))\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting langchain_mistralai (from -r requirements.txt (line 3))\n",
            "  Downloading langchain_mistralai-0.2.11-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain->-r requirements.txt (line 1)) (0.3.68)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain->-r requirements.txt (line 1)) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain->-r requirements.txt (line 1)) (0.4.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain->-r requirements.txt (line 1)) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain->-r requirements.txt (line 1)) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from langchain_mistralai->-r requirements.txt (line 3)) (0.21.2)\n",
            "Requirement already satisfied: httpx<1,>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langchain_mistralai->-r requirements.txt (line 3)) (0.28.1)\n",
            "Collecting httpx-sse<1,>=0.3.1 (from langchain_mistralai->-r requirements.txt (line 3))\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain_mistralai->-r requirements.txt (line 3)) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain_mistralai->-r requirements.txt (line 3)) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain_mistralai->-r requirements.txt (line 3)) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain_mistralai->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain_mistralai->-r requirements.txt (line 3)) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain->-r requirements.txt (line 1)) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain->-r requirements.txt (line 1)) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain->-r requirements.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 1)) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 1)) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 1)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 1)) (3.2.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15.1->langchain_mistralai->-r requirements.txt (line 3)) (0.33.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai->-r requirements.txt (line 3)) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai->-r requirements.txt (line 3)) (2025.3.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai->-r requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai->-r requirements.txt (line 3)) (1.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.2->langchain_mistralai->-r requirements.txt (line 3)) (1.3.1)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading langchain_mistralai-0.2.11-py3-none-any.whl (16 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: python-dotenv, httpx-sse, langchain_mistralai\n",
            "Successfully installed httpx-sse-0.4.1 langchain_mistralai-0.2.11 python-dotenv-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternatively, api keys can be read from .env file\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "os.environ['LANGCHAIN_API_KEY']=os.getenv('LANGCHAIN_API_KEY')\n",
        "os.environ['MISTRAL_API_KEY']=os.getenv('MISTRAL_API_KEY')\n",
        "# langsmith tracing\n",
        "os.environ['LANGCHAIN_TRACING_V2']=os.getenv('LANGCHAIN_TRACING_V2')\n",
        "os.environ['LANGSMITH_PROJECT']=os.getenv('LANGSMITH_PROJECT')"
      ],
      "metadata": {
        "id": "HYrWHZ5k9q91"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_mistralai import ChatMistralAI\n",
        "\n",
        "llm = ChatMistralAI(\n",
        "    model=\"mistral-large-latest\"\n",
        ")\n",
        "print(llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q_tlAyCCD9W",
        "outputId": "66c16d15-e2da-4841-f7e8-06db7bb03416"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client=<httpx.Client object at 0x7cab64256b50> async_client=<httpx.AsyncClient object at 0x7cab30b24410> mistral_api_key=SecretStr('**********') endpoint='https://api.mistral.ai/v1' model='mistral-large-latest' model_kwargs={}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get response from llm\n",
        "\n",
        "llm.invoke('tell me a thriller story in 3 lines about the topic: dashing lane')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMByHvkQC2u5",
        "outputId": "262296f0-8e4d-438f-9f44-8116e692d8b7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='In the dead of night, a lone driver, Alex, races down the infamous \"Dashing Lane,\" a deserted highway known for its mysterious disappearances. Suddenly, Alex\\'s headlights flicker, revealing a chilling figure standing motionless in the middle of the road. As Alex swerves to avoid the figure, the car careens off the road, and Alex awakens in an abandoned town, realizing the true horror of Dashing Lane is not the road itself, but the sinister force that controls it.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 20, 'total_tokens': 130, 'completion_tokens': 110}, 'model_name': 'mistral-large-latest', 'model': 'mistral-large-latest', 'finish_reason': 'stop'}, id='run--aa043174-8cac-42f9-863c-08eeb3ad9fe6-0', usage_metadata={'input_tokens': 20, 'output_tokens': 110, 'total_tokens': 130})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jD4X5tFU9Jli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat prompt template\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant that translates {input_language} to {output_language}.\"),\n",
        "    (\"human\", \"{text}\"),\n",
        "])\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7k2sdKcL4nS",
        "outputId": "b4a84673-5500-4ea2-cf0b-318787b278a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['input_language', 'output_language', 'text'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input_language', 'output_language'], input_types={}, partial_variables={}, template='You are a helpful assistant that translates {input_language} to {output_language}.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt|llm\n",
        "response = chain.invoke({\"input_language\": \"English\", \"output_language\": \"French\", \"text\": \"I love programming.\"})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNw3HAdYMsNl",
        "outputId": "d29146ec-7f5b-4702-80ea-98bc9032b423"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"I love programming. = J'aime la programmation.\\n\\nHere's a breakdown:\\n- I love = J'aime\\n- programming = la programmation\" additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 21, 'total_tokens': 61, 'completion_tokens': 40}, 'model_name': 'mistral-large-latest', 'model': 'mistral-large-latest', 'finish_reason': 'stop'} id='run--80db86cd-2a93-44ca-9fbf-84efbc18b4ed-0' usage_metadata={'input_tokens': 21, 'output_tokens': 40, 'total_tokens': 61}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# default o/p parser - stroutput parser\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "output_parser = StrOutputParser()\n",
        "chain=prompt|llm|output_parser\n",
        "response = chain.invoke({\"input_language\": \"English\", \"output_language\": \"French\", \"text\": \"Would you like to have a coffee?.\"})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "180K3YdfO1p4",
        "outputId": "e2543c68-1f0a-4ea3-fb04-d09e7d92233a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In French, \"Would you like to have a coffee?\" translates to:\n",
            "\n",
            "\"Voudriez-vous prendre un café?\"\n",
            "\n",
            "Here's a breakdown:\n",
            "- \"Would you like\" = \"Voudriez-vous\"\n",
            "- \"to have\" = \"prendre\"\n",
            "- \"a coffee\" = \"un café\"\n"
          ]
        }
      ]
    }
  ]
}